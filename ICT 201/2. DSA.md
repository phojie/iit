---
uuid: " 20010101000000"
created_at: 2023-09-09T07:28:47
updated_at: 2023-09-09T07:28:47
aliases: 
tags:
  - mscs/lessons
---
---

## Array & Linked list

**Big O notation** is a mathematical notation used in computer science and mathematics to describe the upper bound of the time complexity or space complexity of an algorithm or function. It is a way to analyze and compare algorithms in terms of their efficiency and performance as their input size grows. The notation is typically denoted as "O(f(n))," where "f(n)" represents a mathematical function that describes the growth rate of resource usage (usually time or space) as a function of the input size "n."

Here are the two primary aspects of Big O notation:

1. Time Complexity (T(n)): It describes how the runtime of an algorithm grows concerning the input size. The time complexity is expressed as O(f(n)), where "f(n)" is a function that represents the upper bound of the number of basic operations an algorithm performs as a function of the input size "n."

Common examples of time complexities include:
   - O(1): Constant time complexity, indicating that the algorithm's runtime remains constant regardless of the input size.
   - O(log n): Logarithmic time complexity, often associated with algorithms that divide the input in half at each step, like binary search.
   - O(n): Linear time complexity, indicating that the runtime grows linearly with the input size.
   - O(n^2): Quadratic time complexity, indicating that the runtime grows with the square of the input size.
   - O(2^n): Exponential time complexity, where the runtime grows exponentially with the input size.

2. Space Complexity (S(n)): It describes how the memory (space) used by an algorithm or function grows concerning the input size. Like time complexity, space complexity is also expressed as O(f(n)), where "f(n)" represents the upper bound of the amount of memory used as a function of the input size "n."

Common examples of space complexities include:
   - O(1): Constant space complexity, indicating that the algorithm uses a fixed amount of memory regardless of the input size.
   - O(n): Linear space complexity, indicating that the memory usage grows linearly with the input size.
   - O(n^2): Quadratic space complexity, indicating that the memory usage grows with the square of the input size.

>Big O notation provides a standardized way to discuss and analyze algorithmic efficiency. It allows developers and computer scientists to make informed decisions when choosing algorithms for specific tasks based on their scalability and resource consumption. Algorithms with lower time and space complexities are generally preferred for larger input sizes, as they tend to be more efficient in practice.

**Time Complexities:**

1. **O(1) - Constant Time Complexity:**
   
```python
def get_first_element(arr):
    return arr[0]
```

2. **O(log n) - Logarithmic Time Complexity:**

```python
def binary_search(arr, target):
    left, right = 0, len(arr) - 1
    while left <= right:
        mid = (left + right) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
    return -1
```

3. **O(n) - Linear Time Complexity:**

```python
def linear_search(arr, target):
    for i in range(len(arr)):
        if arr[i] == target:
            return i
    return -1
```

4. **O(n^2) - Quadratic Time Complexity:**

```python
def bubble_sort(arr):
    n = len(arr)
    for i in range(n):
        for j in range(0, n-i-1):
            if arr[j] > arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j]
```

**Space Complexities:**

1. **O(1) - Constant Space Complexity:**

```python
def add_two_numbers(a, b):
    result = a + b
    return result
```

2. **O(n) - Linear Space Complexity:**

```python
def create_array(n):
    arr = []
    for i in range(n):
        arr.append(i)
    return arr
```

3. **O(n^2) - Quadratic Space Complexity:**

```python
def create_2d_matrix(n):
    matrix = [[0] * n for _ in range(n)]
    return matrix
```

>These code examples demonstrate how different time and space complexities are represented in Python code. Depending on the specific algorithm or function, you may encounter different complexities, and understanding them can help you assess the efficiency and scalability of your code.

----

| Big O Notation  | Time Complexity      | Space Complexity     | Example                                          |
|-----------------|-----------------------|----------------------|--------------------------------------------------|
| O(1)            | Constant              | Constant             | Accessing the first element of an array         |
| O(log n)        | Logarithmic           | Constant             | Binary search in a sorted array                |
| O(n)            | Linear                | Linear               | Linear search in an array                      |
| O(n^2)          | Quadratic             | Quadratic            | Bubble sort algorithm                          |
| O(2^n)          | Exponential           | Exponential          | Brute-force solution to the Traveling Salesman Problem |
| O(1)            | Constant              | Constant             | Adding two numbers                             |
| O(n)            | Linear                | Linear               | Creating an array of size n                    |
| O(n^2)          | Quadratic             | Quadratic            | Creating a 2D matrix of size n x n             |

>Please note that the examples provided in the table correspond to the code examples and explanations mentioned earlier in the conversation. This table serves as a reference to understand how different complexities are categorized and what types of algorithms or operations they are associated with.

--- 

Arrays and linked lists are both data structures used for storing collections of elements, but they have different characteristics, advantages, and trade-offs. The choice between using an array or a linked list depends on the specific requirements of your application. Let's compare these two data structures:

**Arrays:**

1. **Contiguous Memory:** Arrays store elements in contiguous memory locations. This means that elements are stored right next to each other in memory, allowing for efficient random access using an index. Accessing an element by index in an array typically has a time complexity of O(1).

2. **Fixed Size:** In many programming languages, arrays have a fixed size, meaning that you need to specify the size of the array when you create it. This can lead to problems if you need to dynamically resize the collection.

3. **Dynamic Arrays:** Some languages offer dynamic arrays (e.g., Python's `list` or Java's `ArrayList`) that automatically resize when needed. This flexibility comes at the cost of occasional resizing operations, which can lead to a time complexity of O(n) for certain operations when resizing is required.

4. **Insertions and Deletions:** Insertions and deletions in the middle of an array can be less efficient (O(n)) because elements may need to be shifted to accommodate the change in position.

5. **Memory Overhead:** Arrays can have less memory overhead compared to linked lists because they do not require additional pointers to connect elements.

**Linked Lists:**

1. **Dynamic Size:** Linked lists can easily accommodate a dynamic number of elements. New elements can be added or removed without the need to resize the data structure.

2. **Non-Contiguous Memory:** Elements in a linked list are not stored in contiguous memory locations. Each element contains a reference (pointer) to the next element in the list. This makes linked lists more flexible for insertions and deletions.

3. **Random Access:** Linked lists do not support efficient random access by index. To access an element, you must traverse the list from the beginning, which has a time complexity of O(n).

4. **Variations:** There are different types of linked lists, including singly linked lists (each element points to the next), doubly linked lists (each element points to both the next and previous), and circular linked lists (the last element points back to the first).

5. **Memory Overhead:** Linked lists have more memory overhead compared to arrays because each element requires an additional pointer to the next (and possibly previous) element.

>In summary, you should choose between an array and a linked list based on your specific use case. Use an array when you need efficient random access, have a fixed or predictable size, and want to minimize memory overhead. Use a linked list when you require dynamic sizing, frequent insertions and deletions, or when you don't need fast random access by index. Additionally, consider hybrid data structures like dynamic arrays (e.g., ArrayList) that provide some of the benefits of both arrays and linked lists.

- **Array** : best in performance poor in memory
- **Linked list** : best in memory poor in performance

## Stack
---

Summarizing the key differences between stacks and queues:

| Characteristic      | Stack                                                                                               | Queue                                                                               |
| ------------------- | --------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------- |
| Order of Processing | Last-In, First-Out (LIFO)                                                                           | First-In, First-Out (FIFO)                                                          |
| Main Operations     | `push`: Adds to the top. `pop`: Removes and returns from the top.                                   | `enqueue`: Adds to the back. `dequeue`: Removes and returns from the front.         |
| Visual Analogy      | Stack of plates.                                                                                    | People waiting in a queue.                                                          |
| Typical Use Cases   | Function call management (call stack), undo/redo functionality, parsing and evaluating expressions. | Task scheduling (task queue), print job management, breadth-first search in graphs. |

This table provides a clear overview of the fundamental differences between stacks and queues, including their order of processing, primary operations, visual analogies, and common use cases.

**Additional**: 
- Stack is either `array` or `linked list`
- Push and pop o(1) , and maybe o(n)
- Queue is also `array` or `linked list`
- Queue as an `array` > queue as an `linked list`
- if `( ` or `)` it should be push
- n = 1+2+3+4+n... === n(n+1) / 2

Other DS to be discussed in the future:
- Ordered list
- Sorted list
	 
Graph & Trees
